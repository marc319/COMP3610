{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def read_dataframe(url) -> pd.DataFrame:\n",
    "    liar_dataset_url = f\"https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/{url}\"\n",
    "    data = pd.read_csv(liar_dataset_url, sep='\\t', header=None)\n",
    "    #data = pd.read_csv(tsv_file, delimiter='\\t', dtype=object)\n",
    "    data.fillna(\"\", inplace=True)\n",
    "    data.columns = [\n",
    "        'id',                # Column 1: the ID of the statement ([ID].json).\n",
    "        'label',            \n",
    "        'statement',         \n",
    "        'subjects',          \n",
    "        'speaker',           \n",
    "        'speaker_job_title', \n",
    "        'state_info',        \n",
    "        'party_affiliation', \n",
    "        'barelyTrueCount', \n",
    "        'falseCount', \n",
    "        'halfTruecCount', \n",
    "        'mostlyTrueCount',\n",
    "        'pantsOnFireCount', \n",
    "        'context' # the context (venue / location of the speech or statement).\n",
    "    ]\n",
    "    return data\n",
    "\n",
    "data= read_dataframe(\"train.tsv\")\n",
    "data.info()\n",
    "\n",
    "def TF(value):\n",
    "    if value == 'pants-fire':\n",
    "        return 0\n",
    "    elif value == 'false':\n",
    "        return 0\n",
    "    elif value == 'barely-true':\n",
    "        return 0\n",
    "    elif value == 'half-true':\n",
    "        return 1\n",
    "    elif value == 'mostly-true':\n",
    "        return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "data['T/F'] = data['label'].apply(TF)\n",
    "\n",
    "x = data['statement']\n",
    "y = data['T/F']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.25)\n",
    "\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "xv_test = vectorization.transform(x_test)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train, y_train)\n",
    "pred_lr = LR.predict(xv_test)\n",
    "LR.score(xv_test, y_test)\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "\n",
    "SVM = SVC()\n",
    "SVM.fit(xv_train, y_train)\n",
    "pred_svm = SVM.predict(xv_test)\n",
    "SVM.score(xv_test, y_test)\n",
    "print(classification_report(y_test, pred_svm))\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\", \" \", text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '',text)\n",
    "    return text\n",
    "\n",
    "def labels(outcome):\n",
    "    if outcome == 0:\n",
    "        return \"Fake News\"\n",
    "    elif outcome == 1:\n",
    "        return \"Real News\"\n",
    "\n",
    "def testing(news):\n",
    "    expriment_news = {\"text\":[news]}\n",
    "    new_def_test = pd.DataFrame(expriment_news)\n",
    "    new_def_test[\"text\"] = new_def_test[\"text\"].apply(clean)\n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    new_xv_test = vectorization.transform(new_x_test)\n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_SVM = SVM.predict(new_xv_test)\n",
    "    return pred_LR, pred_SVM\n",
    "    \n",
    "\n",
    "test_data= read_dataframe(\"test.tsv\")\n",
    "LR_array = []\n",
    "SVM_array =[]\n",
    "\n",
    "for x in test_data['statement']:\n",
    "    pred_LR, pred_SVM = testing(x)\n",
    "    LR_array.append(pred_LR)\n",
    "    SVM_array.append(pred_SVM)\n",
    "    print (\"\\n\\nLR Prediction: {} \\nSVM Prediction: {}\".format(labels(pred_LR[0]), labels(pred_SVM[0])))\n",
    "\n",
    "test_data['LR_Prediction'] = LR_array\n",
    "test_data['SVM_Prediction'] = SVM_array\n",
    "\n",
    "\n",
    "LR_real_pred=0\n",
    "real =0\n",
    "LR_fake_pred =0\n",
    "fake = 0\n",
    "\n",
    "for data in test_data['LR_Prediction']:\n",
    "    if data == 1:\n",
    "        LR_real_pred += 1\n",
    "    if data == 0:\n",
    "        LR_fake_pred += 1\n",
    "                    \n",
    "val_data= read_dataframe(\"valid.tsv\")\n",
    "\n",
    "val_data['T/F'] = val_data['label'].apply(TF)\n",
    "\n",
    "for data in val_data['T/F']:\n",
    "    if data == 1:\n",
    "        real += 1\n",
    "    if data == 0:\n",
    "        fake += 1\n",
    "\n",
    "categories = ['Real News', 'Fake News']\n",
    "actual_values = [real, fake]\n",
    "predicted_values = [LR_real_pred, LR_fake_pred]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, actual_values, width, label='Actual')\n",
    "rects2 = ax.bar(x + width/2, predicted_values, width, label='Predicted')\n",
    "\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Real News vs Predicted Real News and Fake News vs Predicted Fake News using Logistic Regression Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "SVM_real_pred=0\n",
    "SVM_fake_pred =0\n",
    "\n",
    "for data in test_data['SVM_Prediction']:\n",
    "    if data == 1:\n",
    "        SVM_real_pred += 1\n",
    "    if data == 0:\n",
    "        SVM_fake_pred += 1\n",
    "                    \n",
    "\n",
    "categories = ['Real News', 'Fake News']\n",
    "actual_values = [real, fake]\n",
    "predicted_values = [SVM_real_pred, SVM_fake_pred]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, actual_values, width, label='Actual')\n",
    "rects2 = ax.bar(x + width/2, predicted_values, width, label='Predicted')\n",
    "\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Real News vs Predicted Real News and Fake News vs Predicted Fake News using SVM Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, pred_lr)\n",
    "\n",
    "cm_svm = confusion_matrix(y_test, pred_svm)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm_lr, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(cm_svm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n",
    "plt.title(\"Confusion Matrix - Support Vector Machines\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "conf_matrix = pd.crosstab(y_test, pred_lr, rownames=['Actual'], colnames=['Predicted'])\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, pred_svm)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=\"Logistic Regression (AUC = %0.2f)\" % roc_auc_lr)\n",
    "plt.plot(fpr_svm, tpr_svm, label=\"Support Vector Machines (AUC = %0.2f)\" % roc_auc_svm)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y_test, pred_lr)\n",
    "\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_test, pred_svm)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_lr, precision_lr, label=\"Logistic Regression\")\n",
    "plt.plot(recall_svm, precision_svm, label=\"Support Vector Machines\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_regression, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "roc_conf = confusion_matrix(y_test, pred_svm)\n",
    "\n",
    "print(f1_score(y_test,pred_lr))\n",
    "print(f1_score(y_test,pred_svm))\n",
    "\n",
    "print(precision_score(y_test,pred_lr))\n",
    "print(precision_score(y_test,pred_svm))\n",
    "\n",
    "print(recall_score(y_test,pred_lr))\n",
    "print(recall_score(y_test,pred_svm))\n",
    "\n",
    "print(roc_auc_score(y_test,pred_lr))\n",
    "print(roc_auc_score(y_test,pred_svm))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_lr)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_svm)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", x_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", x_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
